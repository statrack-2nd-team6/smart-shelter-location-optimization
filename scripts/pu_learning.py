import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torchvision import models, transforms
from PIL import Image
import pandas as pd
import os

# --- 1. ì„¤ì • ë° ê²½ë¡œ ---
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CSV_PATH = os.path.join(BASE_DIR, "final_pu_dataset.csv")
IMG_DIR = os.path.join(BASE_DIR, "..", "bus_stop_images")

# --- 2. ë°ì´í„°ì…‹ í´ë˜ìŠ¤ ---
class ShelterDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.data = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.data)

    def __getitem__(self, idx):
        file_name = self.data.iloc[idx, 0]
        img_path = os.path.join(self.img_dir, file_name)
        image = Image.open(img_path).convert('RGB')
        label = self.data.iloc[idx, 1]
        
        if self.transform:
            image = self.transform(image)
        return image, torch.tensor(label, dtype=torch.float32), file_name

# --- 3. ì „ì²˜ë¦¬ ë° ë¡œë” ---
transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

dataset = ShelterDataset(CSV_PATH, IMG_DIR, transform=transform)
# CPU í™˜ê²½ì„ ê³ ë ¤í•´ batch_sizeë¥¼ ì¡°ì ˆí•˜ì„¸ìš”.
dataloader = DataLoader(dataset, batch_size=16, shuffle=True)

# --- 4. ëª¨ë¸ ì„¤ì • (ResNet18) ---
model = models.resnet18(weights='IMAGENET1K_V1')
model.fc = nn.Sequential(
    nn.Linear(model.fc.in_features, 1),
    nn.Sigmoid()
)
model = model.to("cpu")

# --- 5. í•™ìŠµ ---
criterion = nn.BCELoss()
optimizer = optim.Adam(model.parameters(), lr=0.001)

print("ğŸš€ ìŠ¤ë§ˆíŠ¸ ì‰¼í„° ë¶„ì„ ëª¨ë¸ í•™ìŠµ ì‹œì‘ (1 Epoch í…ŒìŠ¤íŠ¸)...")
model.train()
for epoch in range(1):
    for i, (images, labels, _) in enumerate(dataloader):
        optimizer.zero_grad()
        outputs = model(images).squeeze()
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        
        if i % 10 == 0:
            print(f"Batch {i}, Loss: {loss.item():.4f}")

# --- 6. ê²°ê³¼ ì¶”ì¶œ (Inference) ---
print("ğŸ” ì „ì²´ í›„ë³´ì§€ ì ìˆ˜ ë§¤ê¸°ëŠ” ì¤‘...")
model.eval()
results = []
with torch.no_grad():
    for images, labels, filenames in dataloader:
        outputs = model(images).squeeze()
        # ì ìˆ˜ê°€ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ ê²½ìš°(ë°°ì¹˜ 1ì¼ ë•Œ) ì²˜ë¦¬
        if outputs.dim() == 0: outputs = outputs.unsqueeze(0)
        
        for name, score, label in zip(filenames, outputs, labels):
            if label == 0: # ì•„ì§ ì„¤ì¹˜ ì•ˆ ëœ ê³³(U)ë§Œ ëŒ€ìƒ
                results.append({'file_name': name, 'score': score.item()})

# --- 7. ìƒìœ„ 10ê°œ ì¶œë ¥ ë° ì €ì¥ ---
top_10 = pd.DataFrame(results).sort_values(by='score', ascending=False).head(10)
print("\nğŸ† [ìŠ¤ë§ˆíŠ¸ ì‰¼í„° ì„¤ì¹˜ ê¶Œì¥ TOP 10]")
print(top_10)

top_10.to_csv(os.path.join(BASE_DIR, "top_candidates.csv"), index=False, encoding='utf-8-sig')
print(f"\nâœ… ë¶„ì„ ì™„ë£Œ! í›„ë³´ ë¦¬ìŠ¤íŠ¸ê°€ 'top_candidates.csv'ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")